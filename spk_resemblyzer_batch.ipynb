{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e9841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from resemblyzer import preprocess_wav, VoiceEncoder\n",
    "from pathlib import Path\n",
    "import json\n",
    "from pydub.utils import make_chunks\n",
    "from scipy.spatial.distance import pdist, squareform, euclidean, cosine\n",
    "from spectralcluster import SpectralClusterer\n",
    "import moviepy.editor as mp\n",
    "# filename = \"file.wav\"\n",
    "from resemblyzer import sampling_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa88b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = mp.VideoFileClip(\"test2.mp4\")\n",
    "# video.audio.write_audiofile(video.filename.split('.')[0]+\".wav\")\n",
    "# filename = video.filename.split('.')[0]+'.wav'\n",
    "# wav_fpath = Path(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e311c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"file.wav\"\n",
    "wav_fpath = Path(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d8e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video.filename.split('.')[0]+'.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80df55f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the voice encoder model on cpu in 0.11 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clusterer = SpectralClusterer(\n",
    "    min_clusters=2,\n",
    "    max_clusters=100,\n",
    "    #p_percentile=0.90,\n",
    "    #gaussian_blur_sigma=1\n",
    "    )\n",
    "\n",
    "encoder = VoiceEncoder(\"cpu\")\n",
    "\n",
    "# a function that splits the audio file into chunks\n",
    "# and applies speech recognition\n",
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunk_length_ms = 120000 # pydub calculates in millisec\n",
    "    chunks = make_chunks(sound, chunk_length_ms) #M\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_json = \"\"\n",
    "    labelling = []\n",
    "    global_label = []\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        print('start preprocessing:' + chunk_filename)\n",
    "        # recognize the chunk\n",
    "        #wav = preprocess_wav(wav_fpath)\n",
    "        wav = preprocess_wav(chunk_filename)\n",
    "        print('preprocessing done:' + chunk_filename)\n",
    "        #wav = audio_chunk\n",
    "        _, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16)\n",
    "        labels = clusterer.predict(cont_embeds)\n",
    "        times = [((s.start + s.stop) / 2) / sampling_rate for s in wav_splits]\n",
    "        \n",
    "        start_time = 0\n",
    "        print('create labels:' + chunk_filename)\n",
    "#         print(times)\n",
    "        perChunkLabel = []\n",
    "        for j,time in enumerate(times):\n",
    "            if j>0 and labels[j]!=labels[j-1]:\n",
    "                temp = [str(labels[j-1]),start_time,time]\n",
    "                perChunkLabel.append(temp)\n",
    "                start_time = time\n",
    "            if j==len(times)-1:\n",
    "                temp = [str(labels[j]),start_time,time]\n",
    "                perChunkLabel.append(temp)\n",
    "#         chunkl.append(len(labelling))   #positions of all the chunks in \n",
    "        labelling.append(perChunkLabel)\n",
    "    \n",
    "    return labelling, chunks, wav\n",
    "    # return the text for all chunks detected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9518cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start preprocessing:audio-chunks/chunk1.wav\n",
      "preprocessing done:audio-chunks/chunk1.wav\n",
      "create labels:audio-chunks/chunk1.wav\n",
      "start preprocessing:audio-chunks/chunk2.wav\n",
      "preprocessing done:audio-chunks/chunk2.wav\n",
      "create labels:audio-chunks/chunk2.wav\n",
      "start preprocessing:audio-chunks/chunk3.wav\n",
      "preprocessing done:audio-chunks/chunk3.wav\n",
      "create labels:audio-chunks/chunk3.wav\n"
     ]
    }
   ],
   "source": [
    "global_label, chunk, wav = get_large_audio_transcription(wav_fpath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with open('labellings/' + filename + '.json', 'w') as fp:\n",
    "#     json.dump(labelling, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b2eec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['1', 0, 37.4],\n",
       "  ['0', 37.4, 40.22],\n",
       "  ['1', 40.22, 40.76],\n",
       "  ['0', 40.76, 42.44],\n",
       "  ['1', 42.44, 43.34],\n",
       "  ['0', 43.34, 48.5],\n",
       "  ['1', 48.5, 49.16],\n",
       "  ['0', 49.16, 60.56],\n",
       "  ['1', 60.56, 96.62],\n",
       "  ['0', 96.62, 96.68],\n",
       "  ['1', 96.68, 96.74],\n",
       "  ['0', 96.74, 98.54],\n",
       "  ['1', 98.54, 99.98],\n",
       "  ['0', 99.98, 104.0],\n",
       "  ['1', 104.0, 110.18]],\n",
       " [['0', 0, 9.38],\n",
       "  ['1', 9.38, 17.06],\n",
       "  ['0', 17.06, 24.68],\n",
       "  ['1', 24.68, 24.8],\n",
       "  ['0', 24.8, 27.2],\n",
       "  ['1', 27.2, 27.5],\n",
       "  ['0', 27.5, 27.56],\n",
       "  ['1', 27.56, 27.68],\n",
       "  ['0', 27.68, 29.48],\n",
       "  ['1', 29.48, 29.54],\n",
       "  ['0', 29.54, 41.96],\n",
       "  ['1', 41.96, 42.56],\n",
       "  ['0', 42.56, 45.02],\n",
       "  ['1', 45.02, 46.88],\n",
       "  ['0', 46.88, 49.22],\n",
       "  ['1', 49.22, 50.9],\n",
       "  ['0', 50.9, 70.88],\n",
       "  ['1', 70.88, 71.24],\n",
       "  ['0', 71.24, 71.42],\n",
       "  ['1', 71.42, 73.52],\n",
       "  ['0', 73.52, 74.0],\n",
       "  ['1', 74.0, 78.08],\n",
       "  ['0', 78.08, 78.26],\n",
       "  ['1', 78.26, 78.32],\n",
       "  ['0', 78.32, 81.2],\n",
       "  ['1', 81.2, 82.46],\n",
       "  ['0', 82.46, 90.5],\n",
       "  ['1', 90.5, 91.46],\n",
       "  ['0', 91.46, 93.14],\n",
       "  ['1', 93.14, 93.5],\n",
       "  ['0', 93.5, 104.24]],\n",
       " [['0', 0, 16.7],\n",
       "  ['1', 16.7, 16.88],\n",
       "  ['0', 16.88, 19.1],\n",
       "  ['1', 19.1, 23.3],\n",
       "  ['0', 23.3, 25.88],\n",
       "  ['1', 25.88, 27.86],\n",
       "  ['0', 27.86, 33.44],\n",
       "  ['1', 33.44, 33.62],\n",
       "  ['0', 33.62, 34.1],\n",
       "  ['1', 34.1, 39.56],\n",
       "  ['0', 39.56, 45.5],\n",
       "  ['1', 45.5, 45.86],\n",
       "  ['0', 45.86, 46.1],\n",
       "  ['1', 46.1, 46.58],\n",
       "  ['0', 46.58, 50.42],\n",
       "  ['1', 50.42, 51.56],\n",
       "  ['0', 51.56, 54.8],\n",
       "  ['1', 54.8, 55.52]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec11e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeBits(chunkLabel): \n",
    "    for i in range(len(chunkLabel)):\n",
    "        if chunkLabel[i][0] =='0': \n",
    "            chunkLabel[i][0] = '1'\n",
    "        else: \n",
    "            chunkLabel[i][0] = '0'\n",
    "    return chunkLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1f48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarity(embed_i, embed_j):\n",
    "    if (1-cosine(embed_i, embed_j)) >= 0.8 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    " \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a499b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if global_label[0][-1][0] == '1':\n",
    "    last_1_time = global_label[0][-1][1:]\n",
    "else: \n",
    "    last_1_time = global_label[0][-2][1:]\n",
    "\n",
    "embed1_time = wav[int(last_1_time[0]*sampling_rate):int(last_1_time[1]*sampling_rate)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2586d496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110.18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = global_label[0][-1][2]\n",
    "constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "645b2ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_global = global_label.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99014bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.38\n",
      "16.7\n"
     ]
    }
   ],
   "source": [
    "shouldChange = []\n",
    "new_global.pop(0)\n",
    "k=0\n",
    "for i in new_global: \n",
    "    start_i, end_i= i[1][1], i[1][2]\n",
    "    print(start_i)\n",
    "    embedi_time = wav[int((start_i+global_label[k][-1][2])*1000):int((end_i+global_label[k][-1][2])*1000)]\n",
    "    k += 1 \n",
    "    \n",
    "    if get_similarity(encoder.embed_utterance(embed1_time), encoder.embed_utterance(embedi_time)): \n",
    "        if i[-1][0] == '0': \n",
    "            # '0' -> '1'\n",
    "            # '1' -> '0'\n",
    "            changeBits(i)\n",
    "            shouldChange.append(True)\n",
    "        else: \n",
    "            shouldChange.append(False)\n",
    "    else: \n",
    "        if i[-1][0] == '0': \n",
    "#             continue\n",
    "            shouldChange.append(False)\n",
    "        else: \n",
    "            shouldChange.append(True)\n",
    "            # '0' -> '1'\n",
    "            # '1' -> '0'\n",
    "            changeBits(i)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8374dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedi_time = wav[int((start_i+global_label[k][-1][2])*sampling_rate):int((end_i+global_label[k][-1][2])*sampling_rate)]\n",
    "get_similarity(encoder.embed_utterance(embed1_time), encoder.embed_utterance(embedi_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce7f537c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['0', 0, 9.38],\n",
       "  ['1', 9.38, 17.06],\n",
       "  ['0', 17.06, 24.68],\n",
       "  ['1', 24.68, 24.8],\n",
       "  ['0', 24.8, 27.2],\n",
       "  ['1', 27.2, 27.5],\n",
       "  ['0', 27.5, 27.56],\n",
       "  ['1', 27.56, 27.68],\n",
       "  ['0', 27.68, 29.48],\n",
       "  ['1', 29.48, 29.54],\n",
       "  ['0', 29.54, 41.96],\n",
       "  ['1', 41.96, 42.56],\n",
       "  ['0', 42.56, 45.02],\n",
       "  ['1', 45.02, 46.88],\n",
       "  ['0', 46.88, 49.22],\n",
       "  ['1', 49.22, 50.9],\n",
       "  ['0', 50.9, 70.88],\n",
       "  ['1', 70.88, 71.24],\n",
       "  ['0', 71.24, 71.42],\n",
       "  ['1', 71.42, 73.52],\n",
       "  ['0', 73.52, 74.0],\n",
       "  ['1', 74.0, 78.08],\n",
       "  ['0', 78.08, 78.26],\n",
       "  ['1', 78.26, 78.32],\n",
       "  ['0', 78.32, 81.2],\n",
       "  ['1', 81.2, 82.46],\n",
       "  ['0', 82.46, 90.5],\n",
       "  ['1', 90.5, 91.46],\n",
       "  ['0', 91.46, 93.14],\n",
       "  ['1', 93.14, 93.5],\n",
       "  ['0', 93.5, 104.24]],\n",
       " [['0', 0, 16.7],\n",
       "  ['1', 16.7, 16.88],\n",
       "  ['0', 16.88, 19.1],\n",
       "  ['1', 19.1, 23.3],\n",
       "  ['0', 23.3, 25.88],\n",
       "  ['1', 25.88, 27.86],\n",
       "  ['0', 27.86, 33.44],\n",
       "  ['1', 33.44, 33.62],\n",
       "  ['0', 33.62, 34.1],\n",
       "  ['1', 34.1, 39.56],\n",
       "  ['0', 39.56, 45.5],\n",
       "  ['1', 45.5, 45.86],\n",
       "  ['0', 45.86, 46.1],\n",
       "  ['1', 46.1, 46.58],\n",
       "  ['0', 46.58, 50.42],\n",
       "  ['1', 50.42, 51.56],\n",
       "  ['0', 51.56, 54.8],\n",
       "  ['1', 54.8, 55.52]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e9b7208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['1', 0, 37.4],\n",
       "  ['0', 37.4, 40.22],\n",
       "  ['1', 40.22, 40.76],\n",
       "  ['0', 40.76, 42.44],\n",
       "  ['1', 42.44, 43.34],\n",
       "  ['0', 43.34, 48.5],\n",
       "  ['1', 48.5, 49.16],\n",
       "  ['0', 49.16, 60.56],\n",
       "  ['1', 60.56, 96.62],\n",
       "  ['0', 96.62, 96.68],\n",
       "  ['1', 96.68, 96.74],\n",
       "  ['0', 96.74, 98.54],\n",
       "  ['1', 98.54, 99.98],\n",
       "  ['0', 99.98, 104.0],\n",
       "  ['1', 104.0, 110.18]],\n",
       " [['0', 0, 9.38],\n",
       "  ['1', 9.38, 17.06],\n",
       "  ['0', 17.06, 24.68],\n",
       "  ['1', 24.68, 24.8],\n",
       "  ['0', 24.8, 27.2],\n",
       "  ['1', 27.2, 27.5],\n",
       "  ['0', 27.5, 27.56],\n",
       "  ['1', 27.56, 27.68],\n",
       "  ['0', 27.68, 29.48],\n",
       "  ['1', 29.48, 29.54],\n",
       "  ['0', 29.54, 41.96],\n",
       "  ['1', 41.96, 42.56],\n",
       "  ['0', 42.56, 45.02],\n",
       "  ['1', 45.02, 46.88],\n",
       "  ['0', 46.88, 49.22],\n",
       "  ['1', 49.22, 50.9],\n",
       "  ['0', 50.9, 70.88],\n",
       "  ['1', 70.88, 71.24],\n",
       "  ['0', 71.24, 71.42],\n",
       "  ['1', 71.42, 73.52],\n",
       "  ['0', 73.52, 74.0],\n",
       "  ['1', 74.0, 78.08],\n",
       "  ['0', 78.08, 78.26],\n",
       "  ['1', 78.26, 78.32],\n",
       "  ['0', 78.32, 81.2],\n",
       "  ['1', 81.2, 82.46],\n",
       "  ['0', 82.46, 90.5],\n",
       "  ['1', 90.5, 91.46],\n",
       "  ['0', 91.46, 93.14],\n",
       "  ['1', 93.14, 93.5],\n",
       "  ['0', 93.5, 104.24]],\n",
       " [['0', 0, 16.7],\n",
       "  ['1', 16.7, 16.88],\n",
       "  ['0', 16.88, 19.1],\n",
       "  ['1', 19.1, 23.3],\n",
       "  ['0', 23.3, 25.88],\n",
       "  ['1', 25.88, 27.86],\n",
       "  ['0', 27.86, 33.44],\n",
       "  ['1', 33.44, 33.62],\n",
       "  ['0', 33.62, 34.1],\n",
       "  ['1', 34.1, 39.56],\n",
       "  ['0', 39.56, 45.5],\n",
       "  ['1', 45.5, 45.86],\n",
       "  ['0', 45.86, 46.1],\n",
       "  ['1', 46.1, 46.58],\n",
       "  ['0', 46.58, 50.42],\n",
       "  ['1', 50.42, 51.56],\n",
       "  ['0', 51.56, 54.8],\n",
       "  ['1', 54.8, 55.52]]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_global.insert(0,global_label[0])\n",
    "new_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e80d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinlabels(orderedLabelling):\n",
    "    combinedLabellings = []\n",
    "    secondsCount= 0\n",
    "    for i in range(noOfFiles):\n",
    "        tempArray = orderedLabelling[i]\n",
    "        isSameAsLastSpeaker=False\n",
    "        \n",
    "        if (len(combinedLabellings) == 0):\n",
    "            combinedLabellings.extend(tempArray)\n",
    "            \n",
    "        else:\n",
    "            if (combinedLabellings[len(combinedLabellings)-1][0] == tempArray[0][0]):\n",
    "                combinedLabellings[len(combinedLabellings)-1][2] = combinedLabellings[len(combinedLabellings)-1][2]+ tempArray[0][2]\n",
    "                isSameAsLastSpeaker=True\n",
    "            for j in range(len(tempArray)):\n",
    "                if (j > 0 or isSameAsLastSpeaker == False):\n",
    "                    tempArray[j][1] = tempArray[j][1] + secondsCount # 135.5*(i)\n",
    "                    tempArray[j][2] = tempArray[j][2] +secondsCount # 135.5*(i)\n",
    "                    combinedLabellings.append(tempArray[j])\n",
    "        print( combinedLabellings[len(combinedLabellings)-1][2])\n",
    "        secondsCount = combinedLabellings[len(combinedLabellings)-1][2]\n",
    "    return combinedLabellings\n",
    "\n",
    "def createLabellings(filepath):\n",
    "    for i in range(noOfFiles):\n",
    "        with open(filepath +'/interview' + str(i) + '.json', 'r') as data_file:\n",
    "            json_data = data_file.read()\n",
    "        samplelabellings.append(json.loads(json_data))\n",
    "noOfFiles = len(new_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e07b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.18\n",
      "214.42000000000002\n",
      "269.94\n",
      "[['1', 0, 37.4], ['0', 37.4, 40.22], ['1', 40.22, 40.76], ['0', 40.76, 42.44], ['1', 42.44, 43.34], ['0', 43.34, 48.5], ['1', 48.5, 49.16], ['0', 49.16, 60.56], ['1', 60.56, 96.62], ['0', 96.62, 96.68], ['1', 96.68, 96.74], ['0', 96.74, 98.54], ['1', 98.54, 99.98], ['0', 99.98, 104.0], ['1', 104.0, 110.18], ['0', 110.18, 119.56], ['1', 119.56, 127.24000000000001], ['0', 127.24000000000001, 134.86], ['1', 134.86, 134.98000000000002], ['0', 134.98000000000002, 137.38], ['1', 137.38, 137.68], ['0', 137.68, 137.74], ['1', 137.74, 137.86], ['0', 137.86, 139.66], ['1', 139.66, 139.72], ['0', 139.72, 152.14000000000001], ['1', 152.14000000000001, 152.74], ['0', 152.74, 155.20000000000002], ['1', 155.20000000000002, 157.06], ['0', 157.06, 159.4], ['1', 159.4, 161.08], ['0', 161.08, 181.06], ['1', 181.06, 181.42000000000002], ['0', 181.42000000000002, 181.60000000000002], ['1', 181.60000000000002, 183.7], ['0', 183.7, 184.18], ['1', 184.18, 188.26], ['0', 188.26, 188.44], ['1', 188.44, 188.5], ['0', 188.5, 191.38], ['1', 191.38, 192.64], ['0', 192.64, 200.68], ['1', 200.68, 201.64], ['0', 201.64, 203.32], ['1', 203.32, 203.68], ['0', 203.68, 231.12], ['1', 231.12, 231.3], ['0', 231.3, 233.52], ['1', 233.52, 237.72000000000003], ['0', 237.72000000000003, 240.3], ['1', 240.3, 242.28000000000003], ['0', 242.28000000000003, 247.86], ['1', 247.86, 248.04000000000002], ['0', 248.04000000000002, 248.52], ['1', 248.52, 253.98000000000002], ['0', 253.98000000000002, 259.92], ['1', 259.92, 260.28000000000003], ['0', 260.28000000000003, 260.52000000000004], ['1', 260.52000000000004, 261.0], ['0', 261.0, 264.84000000000003], ['1', 264.84000000000003, 265.98], ['0', 265.98, 269.22], ['1', 269.22, 269.94]]\n"
     ]
    }
   ],
   "source": [
    "combinedLabellings = joinlabels(new_global)\n",
    "print(combinedLabellings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "691c2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i in combinedLabellings:\n",
    "        if(i[2]-i[1]<1):\n",
    "            combinedLabellings.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c35c9af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 0, 37.4],\n",
       " ['0', 37.4, 40.22],\n",
       " ['0', 40.76, 42.44],\n",
       " ['0', 43.34, 48.5],\n",
       " ['0', 49.16, 60.56],\n",
       " ['1', 60.56, 96.62],\n",
       " ['1', 96.68, 96.74],\n",
       " ['0', 96.74, 98.54],\n",
       " ['1', 98.54, 99.98],\n",
       " ['0', 99.98, 104.0],\n",
       " ['1', 104.0, 110.18],\n",
       " ['0', 110.18, 119.56],\n",
       " ['1', 119.56, 127.24000000000001],\n",
       " ['0', 127.24000000000001, 134.86],\n",
       " ['0', 134.98000000000002, 137.38],\n",
       " ['0', 137.68, 137.74],\n",
       " ['0', 137.86, 139.66],\n",
       " ['0', 139.72, 152.14000000000001],\n",
       " ['0', 152.74, 155.20000000000002],\n",
       " ['1', 155.20000000000002, 157.06],\n",
       " ['0', 157.06, 159.4],\n",
       " ['1', 159.4, 161.08],\n",
       " ['0', 161.08, 181.06],\n",
       " ['0', 181.42000000000002, 181.60000000000002],\n",
       " ['1', 181.60000000000002, 183.7],\n",
       " ['1', 184.18, 188.26],\n",
       " ['1', 188.44, 188.5],\n",
       " ['0', 188.5, 191.38],\n",
       " ['1', 191.38, 192.64],\n",
       " ['0', 192.64, 200.68],\n",
       " ['0', 201.64, 203.32],\n",
       " ['0', 203.68, 231.12],\n",
       " ['0', 231.3, 233.52],\n",
       " ['1', 233.52, 237.72000000000003],\n",
       " ['0', 237.72000000000003, 240.3],\n",
       " ['1', 240.3, 242.28000000000003],\n",
       " ['0', 242.28000000000003, 247.86],\n",
       " ['0', 248.04000000000002, 248.52],\n",
       " ['1', 248.52, 253.98000000000002],\n",
       " ['0', 253.98000000000002, 259.92],\n",
       " ['0', 260.28000000000003, 260.52000000000004],\n",
       " ['0', 261.0, 264.84000000000003],\n",
       " ['1', 264.84000000000003, 265.98],\n",
       " ['0', 265.98, 269.22]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedLabellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc68b2ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-36ca349ad48e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_fpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-36ca349ad48e>\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m        \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m'spk'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m               \u001b[0;32mif\u001b[0m \u001b[0mcosine_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk_sig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"speaker 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "import sys\n",
    "import os\n",
    "import wave\n",
    "import subprocess\n",
    "import srt\n",
    "import json\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "\n",
    "wav_fpath = \"file.wav\"\n",
    "SetLogLevel(-1)\n",
    "\n",
    "if not os.path.exists(\"model\"):\n",
    "    print (\"Please download the model from https://alphacephei.com/vosk/models and unpack as 'model' in the current folder.\")\n",
    "    exit (1)\n",
    "\n",
    "sample_rate=16000\n",
    "model = Model(\"/home/milindsoni/Documents/wisepal_all_features/wisepal/Resemblyzer-master/python/example/model\")\n",
    "rec = KaldiRecognizer(model, sample_rate,\"flipkart\")\n",
    "rec.SetWords(True)\n",
    "# sys.argv[1],\n",
    "process = subprocess.Popen(['ffmpeg', '-loglevel', 'quiet', '-i', wav_fpath ,\n",
    "                            '-ar', str(sample_rate) , '-ac', '1', '-f', 's16le', '-'],\n",
    "                            stdout=subprocess.PIPE)\n",
    "#rec = KaldiRecognizer(model, 16000, \"zero oh one two three four five six seven eight nine\")\n",
    "\n",
    "WORDS_PER_LINE = 7\n",
    "\n",
    "def transcribe():\n",
    "    results = []\n",
    "    subs = []\n",
    "    while True:\n",
    "       data = process.stdout.read(4000)\n",
    "       if len(data) == 0:\n",
    "           break\n",
    "       if rec.AcceptWaveform(data):\n",
    "           results.append(rec.Result())\n",
    "    results.append(rec.FinalResult())\n",
    "\n",
    "    for i, res in enumerate(results):\n",
    "       jres = json.loads(res)\n",
    "       if not 'result' in jres:\n",
    "           continue\n",
    "       words = jres['result']\n",
    "       for j in range(0, len(words), WORDS_PER_LINE):\n",
    "           line = words[j : j + WORDS_PER_LINE] \n",
    "           s = srt.Subtitle(index=len(subs), \n",
    "                   content=\" \".join([l['word'] for l in line]),\n",
    "                   start=datetime.timedelta(seconds=line[0]['start']), \n",
    "                   end=datetime.timedelta(seconds=line[-1]['end']))\n",
    "           subs.append(s)\n",
    "    return subs\n",
    "\n",
    "# \n",
    "with open(wav_fpath.split('.')[0]+ '.txt', 'w') as f:\n",
    "    f.write((srt.compose(transcribe())))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e43fe41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-709dc09212cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# hellow?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# transcrib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msubs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subs' is not defined"
     ]
    }
   ],
   "source": [
    "# print(srt.compose(transcribe()))\n",
    "# hellow? \n",
    "# transcrib\n",
    "subs.transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff20f70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b3337e146522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subs' is not defined"
     ]
    }
   ],
   "source": [
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7548e525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 0, 37.4],\n",
       " ['0', 37.4, 40.22],\n",
       " ['0', 40.76, 42.44],\n",
       " ['0', 43.34, 48.5],\n",
       " ['0', 49.16, 60.56],\n",
       " ['1', 60.56, 96.62],\n",
       " ['1', 96.68, 96.74],\n",
       " ['0', 96.74, 98.54],\n",
       " ['1', 98.54, 99.98],\n",
       " ['0', 99.98, 104.0],\n",
       " ['1', 104.0, 110.18],\n",
       " ['0', 110.18, 119.56],\n",
       " ['1', 119.56, 127.24000000000001],\n",
       " ['0', 127.24000000000001, 134.86],\n",
       " ['0', 134.98000000000002, 137.38],\n",
       " ['0', 137.68, 137.74],\n",
       " ['0', 137.86, 139.66],\n",
       " ['0', 139.72, 152.14000000000001],\n",
       " ['0', 152.74, 155.20000000000002],\n",
       " ['1', 155.20000000000002, 157.06],\n",
       " ['0', 157.06, 159.4],\n",
       " ['1', 159.4, 161.08],\n",
       " ['0', 161.08, 181.06],\n",
       " ['0', 181.42000000000002, 181.60000000000002],\n",
       " ['1', 181.60000000000002, 183.7],\n",
       " ['1', 184.18, 188.26],\n",
       " ['1', 188.44, 188.5],\n",
       " ['0', 188.5, 191.38],\n",
       " ['1', 191.38, 192.64],\n",
       " ['0', 192.64, 200.68],\n",
       " ['0', 201.64, 203.32],\n",
       " ['0', 203.68, 231.12],\n",
       " ['0', 231.3, 233.52],\n",
       " ['1', 233.52, 237.72000000000003],\n",
       " ['0', 237.72000000000003, 240.3],\n",
       " ['1', 240.3, 242.28000000000003],\n",
       " ['0', 242.28000000000003, 247.86],\n",
       " ['0', 248.04000000000002, 248.52],\n",
       " ['1', 248.52, 253.98000000000002],\n",
       " ['0', 253.98000000000002, 259.92],\n",
       " ['0', 260.28000000000003, 260.52000000000004],\n",
       " ['0', 261.0, 264.84000000000003],\n",
       " ['1', 264.84000000000003, 265.98],\n",
       " ['0', 265.98, 269.22]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedLabellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c16a2a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python3\n",
    "\n",
    "# from vosk import Model, KaldiRecognizer\n",
    "# import sys\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# if not os.path.exists(\"model\"):\n",
    "#     print (\"Please download the model from https://alphacephei.com/vosk/models and unpack as 'model' in the current folder.\")\n",
    "#     exit (1)\n",
    "\n",
    "\n",
    "# model = Model(\"/home/milindsoni/Documents/wisepal_all_features/wisepal/Resemblyzer-master/python/example/model\")\n",
    "\n",
    "# # Large vocabulary free form recognition\n",
    "# rec = KaldiRecognizer(model, 16000)\n",
    "\n",
    "# # You can also specify the possible word list\n",
    "# #rec = KaldiRecognizer(model, 16000, \"zero oh one two three four five six seven eight nine\")\n",
    "# directory = \"temp\"\n",
    "# for filename in os.listdir(directory):\n",
    "#     wf = open(os.path.join(directory,filename), \"rb\")\n",
    "#     wf.read(44) # skip header\n",
    "\n",
    "#     while True:\n",
    "#         data = wf.read(4000)\n",
    "#         if len(data) == 0:\n",
    "#             break\n",
    "#         if rec.AcceptWaveform(data):\n",
    "#             res = json.loads(rec.Result())\n",
    "#             print (res['text'])\n",
    "\n",
    "#     res = json.loads(rec.FinalResult())\n",
    "#     print (res['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc49f4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 0, 37.4],\n",
       " ['0', 37.4, 40.22],\n",
       " ['0', 40.76, 42.44],\n",
       " ['0', 43.34, 48.5],\n",
       " ['0', 49.16, 60.56],\n",
       " ['1', 60.56, 96.62],\n",
       " ['1', 96.68, 96.74],\n",
       " ['0', 96.74, 98.54],\n",
       " ['1', 98.54, 99.98],\n",
       " ['0', 99.98, 104.0],\n",
       " ['1', 104.0, 110.18],\n",
       " ['0', 110.18, 119.56],\n",
       " ['1', 119.56, 127.24000000000001],\n",
       " ['0', 127.24000000000001, 134.86],\n",
       " ['0', 134.98000000000002, 137.38],\n",
       " ['0', 137.68, 137.74],\n",
       " ['0', 137.86, 139.66],\n",
       " ['0', 139.72, 152.14000000000001],\n",
       " ['0', 152.74, 155.20000000000002],\n",
       " ['1', 155.20000000000002, 157.06],\n",
       " ['0', 157.06, 159.4],\n",
       " ['1', 159.4, 161.08],\n",
       " ['0', 161.08, 181.06],\n",
       " ['0', 181.42000000000002, 181.60000000000002],\n",
       " ['1', 181.60000000000002, 183.7],\n",
       " ['1', 184.18, 188.26],\n",
       " ['1', 188.44, 188.5],\n",
       " ['0', 188.5, 191.38],\n",
       " ['1', 191.38, 192.64],\n",
       " ['0', 192.64, 200.68],\n",
       " ['0', 201.64, 203.32],\n",
       " ['0', 203.68, 231.12],\n",
       " ['0', 231.3, 233.52],\n",
       " ['1', 233.52, 237.72000000000003],\n",
       " ['0', 237.72000000000003, 240.3],\n",
       " ['1', 240.3, 242.28000000000003],\n",
       " ['0', 242.28000000000003, 247.86],\n",
       " ['0', 248.04000000000002, 248.52],\n",
       " ['1', 248.52, 253.98000000000002],\n",
       " ['0', 253.98000000000002, 259.92],\n",
       " ['0', 260.28000000000003, 260.52000000000004],\n",
       " ['0', 261.0, 264.84000000000003],\n",
       " ['1', 264.84000000000003, 265.98],\n",
       " ['0', 265.98, 269.22]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = combinedLabellings\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0af36603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "['1', 0, 37.4]\n",
      "['0', 37.4, 60.56]\n",
      "['1', 60.56, 96.74]\n",
      "['0', 96.74, 98.54]\n",
      "['1', 98.54, 99.98]\n",
      "['0', 99.98, 104.0]\n",
      "['1', 104.0, 110.18]\n",
      "['0', 110.18, 119.56]\n",
      "['1', 119.56, 127.24000000000001]\n",
      "['0', 127.24000000000001, 155.20000000000002]\n",
      "['1', 155.20000000000002, 157.06]\n",
      "['0', 157.06, 159.4]\n",
      "['1', 159.4, 161.08]\n",
      "['0', 161.08, 181.60000000000002]\n",
      "['1', 181.60000000000002, 188.5]\n",
      "['0', 188.5, 191.38]\n",
      "['1', 191.38, 192.64]\n",
      "['0', 192.64, 233.52]\n",
      "['1', 233.52, 237.72000000000003]\n",
      "['0', 237.72000000000003, 240.3]\n",
      "['1', 240.3, 242.28000000000003]\n",
      "['0', 242.28000000000003, 248.52]\n",
      "['1', 248.52, 253.98000000000002]\n",
      "['0', 253.98000000000002, 264.84000000000003]\n",
      "['1', 264.84000000000003, 265.98]\n",
      "['0', 265.98, 269.22]\n"
     ]
    }
   ],
   "source": [
    "mappings = combinedLabellings\n",
    "\n",
    "\n",
    "print(len(mappings))\n",
    "\n",
    "def clubbing(mappings):\n",
    "    clubbed = []\n",
    "    starIndex = mappings[0][0]\n",
    "    i = 0\n",
    "\n",
    "    while i<len(mappings):\n",
    "        temp = mappings[i] \n",
    "        k = i+1\n",
    "        while k<len(mappings) and mappings[k][0]==starIndex: \n",
    "            k+=1\n",
    "\n",
    "        i = k\n",
    "\n",
    "        if k>=len(mappings): # explicit ending condition\n",
    "            k = len(mappings)-1\n",
    "            i = len(mappings)\n",
    "            temp[-1] = mappings[-1][-1]\n",
    "            clubbed.append(temp)\n",
    "            break\n",
    "\n",
    "        starIndex = mappings[k][0]\n",
    "        temp[-1] = mappings[k-1][-1]\n",
    "        clubbed.append(temp)\n",
    "    return clubbed\n",
    "clubbed = clubbing(mappings)\n",
    "\n",
    "for i in clubbed: \n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21fa19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clubbed = [['1', 0, 37.4],\n",
    "['0', 37.4, 60.56],\n",
    "['1', 60.56, 96.74],\n",
    "['0', 96.74, 98.54],\n",
    "['1', 98.54, 99.98],\n",
    "['0', 99.98, 104.0],\n",
    "['1', 104.0, 110.18],\n",
    "['0', 110.18, 119.56],\n",
    "['1', 119.56, 127.24000000000001],\n",
    "['0', 127.24000000000001, 155.20000000000002],\n",
    "['1', 155.20000000000002, 157.06],\n",
    "['0', 157.06, 159.4],\n",
    "['1', 159.4, 161.08],\n",
    "['0', 161.08, 181.60000000000002],\n",
    "['1', 181.60000000000002, 188.5],\n",
    "['0', 188.5, 191.38],\n",
    "['1', 191.38, 192.64],\n",
    "['0', 192.64, 233.52],\n",
    "['1', 233.52, 237.72000000000003],\n",
    "['0', 237.72000000000003, 240.3],\n",
    "['1', 240.3, 242.28000000000003],\n",
    "['0', 242.28000000000003, 248.52],\n",
    "['1', 248.52, 253.98000000000002],\n",
    "['0', 253.98000000000002, 264.84000000000003],\n",
    "['1', 264.84000000000003, 265.98],\n",
    "['0', 265.98, 269.22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc536e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caf91d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021</td>\n",
       "      <td>1.681</td>\n",
       "      <td>threats and i want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.916</td>\n",
       "      <td>5.461</td>\n",
       "      <td>what he a squad car and when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.461</td>\n",
       "      <td>8.040</td>\n",
       "      <td>everything that was the coin about fifteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.040</td>\n",
       "      <td>11.070</td>\n",
       "      <td>percent a cult additions to the traditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.073</td>\n",
       "      <td>12.577</td>\n",
       "      <td>were shopping her in the last three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>289.978</td>\n",
       "      <td>291.600</td>\n",
       "      <td>because we are closing it down on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>291.608</td>\n",
       "      <td>292.800</td>\n",
       "      <td>the mobile app so we'll see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>292.800</td>\n",
       "      <td>294.186</td>\n",
       "      <td>yeah all the steps of the user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>294.186</td>\n",
       "      <td>297.744</td>\n",
       "      <td>journey and see if any particular point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>297.744</td>\n",
       "      <td>300.000</td>\n",
       "      <td>before the cart additions has experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         start      end                                    sentence\n",
       "index                                                              \n",
       "1        0.021    1.681                          threats and i want\n",
       "2        2.916    5.461                what he a squad car and when\n",
       "3        5.461    8.040  everything that was the coin about fifteen\n",
       "4        8.040   11.070  percent a cult additions to the traditions\n",
       "5       11.073   12.577         were shopping her in the last three\n",
       "...        ...      ...                                         ...\n",
       "101    289.978  291.600           because we are closing it down on\n",
       "102    291.608  292.800                 the mobile app so we'll see\n",
       "103    292.800  294.186              yeah all the steps of the user\n",
       "104    294.186  297.744     journey and see if any particular point\n",
       "105    297.744  300.000    before the cart additions has experience\n",
       "\n",
       "[105 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filename.split('.')[0] +\n",
    "file = open( 'file.txt', 'r')\n",
    "text = file.readlines()\n",
    "sets = []\n",
    "temp = []\n",
    "for i in range(len(text)): \n",
    "    \n",
    "    if (i+1)%4==0: \n",
    "        sets.append(temp)\n",
    "        temp = []\n",
    "        continue\n",
    "    temp.append(text[i])\n",
    "\n",
    "# filter 1: to remove \\n \n",
    "for i in range(len(sets)):\n",
    "    s = sets[i]\n",
    "    for j in range(3): \n",
    "        sets[i][j] = sets[i][j].split('\\n')[0]\n",
    "# filter 2: to remove --> from time periods!\n",
    "for i in range(len(sets)): \n",
    "    sets[i][1] =  sets[i][1].split(' --> ')\n",
    "\n",
    "def convertString2Time(string): \n",
    "    \n",
    "    s = string.replace(',', '.')\n",
    "    s = s.split(\":\")\n",
    "    # print(s,end = ' ')\n",
    "    mult = (60)**(len(s)-1)\n",
    "    for i in range(len(s)): \n",
    "        s[i] = float(s[i])*mult\n",
    "        mult/=60\n",
    "    # print(s)\n",
    "    return sum(s)\n",
    "# To expand each array!\n",
    "for i in range(len(sets)): \n",
    "    temp = []\n",
    "    for j in range(2):\n",
    "        temp.append(convertString2Time(sets[i][1][j]))\n",
    "    sets[i][1] = temp\n",
    "\n",
    "s = [] \n",
    "for i in sets:\n",
    "    temp = [i[0], i[1][0], i[1][1], i[2]]\n",
    "    s.append(temp)\n",
    "sets = s\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "df = pd.DataFrame(sets, columns = ['index', 'start', 'end', 'sentence'])\n",
    "df = df.set_index('index')\n",
    "display(df)\n",
    "df.to_csv('new_transcript.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16c81096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('new_transcript.csv')\n",
    "k = 0\n",
    "npdf = df.values\n",
    "labels = []\n",
    "for i in range(len(npdf)): \n",
    "    if k>=len(clubbed): \n",
    "        labels.append(clubbed[-1][0])\n",
    "        continue\n",
    "        \n",
    "    if npdf[i][2]<clubbed[k][2]:\n",
    "        labels.append(clubbed[k][0])\n",
    "    elif k<len(clubbed): \n",
    "        labels.append(clubbed[k][0])\n",
    "        k+=1\n",
    "df['labels'] = labels\n",
    "df.to_csv('withLabels.csv', index = False)\n",
    "df = pd.DataFrame(clubbed, columns = ['label', 'star', 'end'])\n",
    "df.to_csv('clubbed.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05e7b870",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'withlabels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ba0eb4a855c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"withlabels.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    648\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'withlabels.csv'"
     ]
    }
   ],
   "source": [
    "transcript = pd.read_csv(\"withlabels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593322b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92039c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e93ed3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
